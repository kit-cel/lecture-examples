{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb79573b",
   "metadata": {},
   "source": [
    "# Simulation of an LDPC Decoder with Application of Transmission over a BEC\n",
    "This code is provided as supplementary material of the lecture Channel Coding - Graph Based Codes (CC-GBC)\n",
    "\n",
    "This code illustrates\n",
    "\n",
    "* Generating LDPC codes according to Gallager's construction\n",
    "* Implementation of a fully sum-product LDPC decoder in Python\n",
    "* Monte-Carloe simulation of the error performance over a binary erasure channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d101bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix, vstack\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd996da",
   "metadata": {},
   "source": [
    "Helper functions needed for the decoder implementation. First `phifun` implements\n",
    "\\begin{equation*}\n",
    "    \\phi(x) = \\ln\\left(\\coth\\left(\\frac{x}{2}\\right)\\right)  \n",
    "\\end{equation*}\n",
    "The second helper function is a modified `sign`function with\n",
    "\\begin{equation*}\n",
    "    \\mathrm{sign}(x) = \\begin{cases}\n",
    "    +1 & x \\geq 0 \\\\\n",
    "    -1 & x < 0\n",
    "    \\end{cases}\n",
    "\\end{equation*}\n",
    "This is necessary as the behavior of the internal sign function for input $x=0$ is often not standardized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a45a2b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phifun(x):\n",
    "    y = 9e9*np.ones_like(x)\n",
    "    y[x>1e-300] = -np.log(np.tanh(x[x>1e-300]/2))\n",
    "    return y\n",
    "\n",
    "\n",
    "def mysign(x):\n",
    "    y = np.ones_like(x)\n",
    "    y[x<0] = -1\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef10276",
   "metadata": {},
   "source": [
    "Sum-product algorithm implemented using plain Python code, no optimization. `CtoV_x` describe the check-node to variable-node messages, separated into sign and amplitude (where `x` is `sign` or `abs`). The variable-node to check-node messages are given by `VtoC`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfc29d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDPC decoder using the full (simplified) update rule, inner loop\n",
    "# completely vectorized but still relatively slow\n",
    "# based on a non-sparse parity-check matrix as input\n",
    "def decode_LDPC_BEC_nosparse(L, H, iterations):\n",
    "    m = H.shape[0]\n",
    "    n = H.shape[1]\n",
    "\n",
    "    # initialize variable to check node messages with channel output\n",
    "    VtoC = np.tile(L.reshape(1, -1), (m, 1)) * H\n",
    "\n",
    "    # main iterations\n",
    "    for _ in range(iterations):\n",
    "        # compute check to variable sum(CtoV,1)node messages\n",
    "        VtoC_sign = mysign(VtoC)\n",
    "        VtoC_abs = np.abs(VtoC)\n",
    "\n",
    "        phiVtoC = phifun(VtoC_abs/2 + (1-H) * 9e9)  # mask out zero entries\n",
    "        phiVtoC_sum = np.sum(phiVtoC, axis=1)\n",
    "\n",
    "        # multiply signs\n",
    "        totalsign_VtoC = np.ones(m)\n",
    "        for i in range(m):\n",
    "            nz = H[i] != 0\n",
    "            totalsign_VtoC[i] = np.prod(VtoC_sign[i, nz])\n",
    "       \n",
    "        CtoV_abs =  phifun((np.tile(phiVtoC_sum.reshape(-1, 1), (1, n)) * H - phiVtoC)/2 + (1-H) * 9e9)\n",
    "        CtoV_sign = np.tile(totalsign_VtoC.reshape(-1, 1), (1, n)) * VtoC_sign\n",
    "        CtoV = CtoV_sign * CtoV_abs       \n",
    "\n",
    "        # compute variable to check node messages, pretty simple\n",
    "        CtoV_sum = np.sum(CtoV,axis=0)\n",
    "        VtoC = (np.tile((CtoV_sum + L).reshape(1, -1), (m, 1)) - CtoV) * H      \n",
    "\n",
    "        # stopping criterion, all parity checks are fulfilled\n",
    "        L_total = CtoV_sum + L\n",
    "        \n",
    "        # binary decision\n",
    "        if np.any(np.abs(L_total) < 1):\n",
    "            # erasures left\n",
    "            xh = np.array([])\n",
    "        else:\n",
    "            xh = L_total < 0\n",
    "    \n",
    "    return xh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0409fcdf",
   "metadata": {},
   "source": [
    "Generate a parity-check matrix according to Gallager's construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0a2c276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a parity-check matrix according to Gallager's method\n",
    "# do not care about 4-cycles\n",
    "def generate_Gallager(dv, dc, n):\n",
    "    assert n % dc == 0, \"n must be a multiple of check node degree dc\"\n",
    "\n",
    "    rows = n // dc\n",
    "    # column indices\n",
    "    jj = np.arange(n)\n",
    "    ii = np.repeat(np.arange(rows), dc)\n",
    "    Ho = coo_matrix((np.ones_like(jj), (ii, jj)), shape=(rows,n)).tocsr()\n",
    "    H = Ho.copy()\n",
    "    for _ in range(dv-1):\n",
    "        H = vstack([H, Ho[:, np.random.permutation(n)]])\n",
    "    \n",
    "    return H"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ef9e44",
   "metadata": {},
   "source": [
    "Carry out Monte-Carlo simulation of the error rate. Simulate 10000 frames an in each frame, we generate a new parity-check matrix. Then carry out decoding for 50 iterations and record the frame error rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddb5c8be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9abf96d79c644b7db32af2db1ffce1a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilon = 0.20: FER = 0.0637\n"
     ]
    }
   ],
   "source": [
    "# parameters of regular LDPC code\n",
    "dv = 3\n",
    "dc = 6\n",
    "\n",
    "# specify epsilon (erasure probability) at which simulation takes place\n",
    "epsilon = 0.2\n",
    "\n",
    "# number of frames to simulate\n",
    "frames = 10000\n",
    "\n",
    "# decoding iterations\n",
    "iterations = 50\n",
    "\n",
    "# length of codeword, attention, must be an integer multiple of dc\n",
    "n = 48\n",
    "\n",
    "\n",
    "# simulate all-zero codeword\n",
    "x = np.zeros(n)\n",
    "\n",
    "errors = 0\n",
    "for _ in tqdm(range(frames)):\n",
    "    # generate parity-check matrix of regular LDPC code\n",
    "    H = generate_Gallager(dv, dc, n)\n",
    "\n",
    "    # erasure channel, first map to bipolar and map to very large value as\n",
    "    # approximation to infinite LLR\n",
    "    y = (1 - 2 * x) * 9999\n",
    "    y[np.random.rand(n) < epsilon] = 0 # erasures (LLR of zero)\n",
    "\n",
    "    xh = decode_LDPC_BEC_nosparse(y, H.toarray(), iterations)\n",
    "\n",
    "    errors = errors + (xh.size == 0)\n",
    "\n",
    "FER = errors / frames    # divide by two, as we may correctly guess the residual erasures\n",
    "print(f\"epsilon = {epsilon:.2f}: FER = {FER:.4g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69f01ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccgbc (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
