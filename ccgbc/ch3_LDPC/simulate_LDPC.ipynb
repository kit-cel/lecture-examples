{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61f6e216",
   "metadata": {},
   "source": [
    "# Simulation of an LDPC Decoder over an AWGN channel\n",
    "This code is provided as supplementary material of the lecture Channel Coding - Graph Based Codes (CC-GBC)\n",
    "\n",
    "This code illustrates\n",
    "\n",
    "* Generating LDPC codes according to Gallager's construction\n",
    "* Implementation of a full sum-product LDPC decoder in Python\n",
    "* Monte-Carloe simulation of the error performance over a binary input AWGN channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d015301b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix, csr_matrix, vstack\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a5271e",
   "metadata": {},
   "source": [
    "Helper functions needed for the decoder implementation. First `phifun` implements\n",
    "\\begin{equation*}\n",
    "    \\phi(x) = \\ln\\left(\\coth\\left(\\frac{x}{2}\\right)\\right)  \n",
    "\\end{equation*}\n",
    "The second helper function is a modified `sign`function with\n",
    "\\begin{equation*}\n",
    "    \\mathrm{sign}(x) = \\begin{cases}\n",
    "    +1 & x \\geq 0 \\\\\n",
    "    -1 & x < 0\n",
    "    \\end{cases}\n",
    "\\end{equation*}\n",
    "This is necessary as the behavior of the internal sign function for input $x=0$ is often not standardized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d3424cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phifun(x):\n",
    "    y = 9e9*np.ones_like(x)\n",
    "    y[x>1e-300] = -np.log(np.tanh(x[x>1e-300]))\n",
    "    return y\n",
    "\n",
    "def mysign(x):\n",
    "    y = np.ones_like(x)\n",
    "    y[x<0] = -1\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23b93c3",
   "metadata": {},
   "source": [
    "Sum-product algorithm implemented using plain Python code, no optimization. `CtoV_x` describe the check-node to variable-node messages, separated into sign and amplitude (where `x` is `sign` or `abs`). The variable-node to check-node messages are given by `VtoC`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e93214c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDPC decoder for the BEC, inner loop\n",
    "# completely vectorized but still relatively slow\n",
    "# based on a sparse matrix as input\n",
    "def decode_LDPC(L, H, iterations):\n",
    "    m, n = H.shape\n",
    "    H = csr_matrix(H)\n",
    "    row_i, col_i = H.nonzero() # get row and column indices\n",
    "\n",
    "    # initialize variable to check node messages with channel output\n",
    "    VtoC = L[col_i].copy()\n",
    "\n",
    "    # numeric stability\n",
    "    epsilon = 1e-12\n",
    "\n",
    "    # main iterations\n",
    "    for _ in range(iterations):\n",
    "        # compute check to variable sum(CtoV,1)node messages\n",
    "        VtoC_sign = np.where(VtoC < 0, -1, 1)\n",
    "        VtoC_abs = np.abs(VtoC)\n",
    "\n",
    "        phiVtoC = np.log(1 / np.tanh(VtoC_abs / 2) + epsilon)\n",
    "        phiVtoC_sum = np.bincount(row_i, weights=phiVtoC, minlength=m)\n",
    "\n",
    "        # multiply signs\n",
    "        totalsign_VtoC = np.ones(m)\n",
    "        np.multiply.at(totalsign_VtoC, row_i, VtoC_sign)\n",
    "        \n",
    "        CtoV_abs = np.log(1 / np.tanh(((phiVtoC_sum[row_i] - phiVtoC) / 2)) + epsilon)\n",
    "\n",
    "        CtoV_sign = totalsign_VtoC[row_i] * VtoC_sign\n",
    "        CtoV = CtoV_sign * CtoV_abs\n",
    "        \n",
    "        # compute variable to check node messages, pretty simple\n",
    "        CtoV_sum = np.bincount(col_i, weights=CtoV, minlength=n)\n",
    "        VtoC = L[col_i] + CtoV_sum[col_i] - CtoV\n",
    "\n",
    "        # stopping criterion, all parity checks are fulfilled\n",
    "        L_total = CtoV_sum + L\n",
    "        \n",
    "        # binary decision\n",
    "        xh = (L_total < 0).astype(int)\n",
    "        if np.all((H @ xh) % 2 == 0):\n",
    "            # all parity-checks fulfilled?\n",
    "            break\n",
    "        \n",
    "    return xh\n",
    "\n",
    "# LDPC decoder using the full (simplified) update rule, inner loop\n",
    "# completely vectorized but still relatively slow\n",
    "# based on a non-sparse parity-check matrix as input\n",
    "def decode_LDPC_nosparse(L, H, iterations):\n",
    "    m, n = H.shape\n",
    "\n",
    "    # initialize variable to check node messages with channel output\n",
    "    VtoC = np.tile(L.reshape(1, -1), (m, 1)) * H\n",
    "\n",
    "    # main iterations\n",
    "    for _ in range(iterations):\n",
    "        # compute check to variable sum(CtoV,1)node messages\n",
    "        VtoC_sign = mysign(VtoC)\n",
    "        VtoC_abs = np.abs(VtoC)\n",
    "\n",
    "        phiVtoC = phifun(VtoC_abs/2 + (1-H) * 9e9)  # mask out zero entries\n",
    "        phiVtoC_sum = np.sum(phiVtoC, axis=1)\n",
    "\n",
    "        # multiply signs\n",
    "        totalsign_VtoC = np.prod(VtoC_sign, axis=1, keepdims=True)\n",
    "       \n",
    "        CtoV_abs = phifun((np.tile(phiVtoC_sum.reshape(-1, 1), (1, n)) * H - phiVtoC)/2 + (1-H) * 9e9)\n",
    "        CtoV_sign = np.tile(totalsign_VtoC.reshape(-1, 1), (1, n)) * VtoC_sign\n",
    "        CtoV = CtoV_sign * CtoV_abs       \n",
    "       \n",
    "        \n",
    "        # compute variable to check node messages, pretty simple\n",
    "        CtoV_sum = np.sum(CtoV,axis=0)\n",
    "        VtoC = (np.tile(CtoV_sum + L, (m,1)) - CtoV) * H     \n",
    "\n",
    "        # stopping criterion, all parity checks are fulfilled\n",
    "        L_total = CtoV_sum + L\n",
    "        \n",
    "        # binary decision\n",
    "        xh = (L_total < 0).astype(int)\n",
    "        if np.all((H @ xh) % 2 == 0):\n",
    "            # all parity-checks fulfilled?\n",
    "            break\n",
    "    \n",
    "    return xh\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a336960f",
   "metadata": {},
   "source": [
    "Generate a parity-check matrix according to Gallager's construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5582eafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a parity-check matrix according to Gallager's method\n",
    "# do not care about 4-cycles\n",
    "def generate_Gallager(dv, dc, n):\n",
    "    if n % dc != 0:\n",
    "        assert False, \"n must be a multiple of check node degree dc\"\n",
    "\n",
    "    rows = n // dc\n",
    "    # column indices\n",
    "    jj = np.arange(n)\n",
    "    ii = np.repeat(np.arange(rows), dc)\n",
    "    Ho = coo_matrix((np.ones_like(jj), (ii, jj)), shape=(rows,n)).tocsr()\n",
    "    H = Ho.copy()\n",
    "    for _ in range(dv-1):\n",
    "        H = vstack([H, Ho[:, np.random.permutation(n)]])\n",
    "    \n",
    "    return H\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4695d55",
   "metadata": {},
   "source": [
    "Carry out Monte-Carlo simulation of the error rate. Simulate 10000 frames an in each frame, we generate a new parity-check matrix. Then carry out decoding for 50 iterations and record the frame error rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b44ff7d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "194c1bac24404e2fb781f716605439fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Es/N0 = -1.00: BER = 0.02214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# parameters of regular LDPC code\n",
    "dv = 3\n",
    "dc = 6\n",
    "\n",
    "# length of codeword, attention, must be an integer multiple of dc\n",
    "n = 1200\n",
    "\n",
    "# specify Es/N0 at which simulation takes place\n",
    "esno_dB = -1\n",
    "\n",
    "# number of frames to simulate\n",
    "frames = 10000\n",
    "\n",
    "# decoding iterations\n",
    "iterations = 5\n",
    "\n",
    "# compute noise standard deviation\n",
    "sigma = np.sqrt(0.5 * 10**(-esno_dB/10))\n",
    "\n",
    "# channel parameter for LLR calculation\n",
    "Lc = 4*(10**(esno_dB/10))\n",
    "\n",
    "# generate parity-check matrix of regular LDPC code\n",
    "H = generate_Gallager(dv, dc, n)\n",
    "\n",
    "# simulate all-zero codeword\n",
    "bits = np.zeros(n) \n",
    "x = 1 - 2*bits #BPSK 0->1 | 1->-1\n",
    "\n",
    "errors = 0\n",
    "for _ in tqdm(range(frames)):\n",
    "    y = x + sigma*np.random.randn(n)\n",
    "\n",
    "    # calculate LLRs\n",
    "    L = Lc * y\n",
    "\n",
    "    xh = decode_LDPC(L.flatten(), H, iterations)\n",
    "    \n",
    "    # alternative using the full matrix (faster for very small matrices,\n",
    "    # slower for large matrices)\n",
    "    #xh = decode_LDPC_nosparse(L.flatten(), H.toarray(), iterations) \n",
    "    \n",
    "    errors = errors + np.sum(xh != bits)\n",
    "\n",
    "BER = errors / (frames * n)\n",
    "print(f\"Es/N0 = {esno_dB:.2f}: BER = {BER:.4g}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6e04eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccgbc (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
