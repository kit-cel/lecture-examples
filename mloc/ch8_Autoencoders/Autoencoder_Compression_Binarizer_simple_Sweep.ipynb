{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Compression using Autoencoders with BPSK\n",
    "\n",
    "This code is provided as supplementary material of the lecture Machine Learning and Optimization in Communications (MLOC).<br>\n",
    "\n",
    "This code illustrates\n",
    "* joint compression and error protection of images by auto-encoders\n",
    "* generation of BPSK symbols using stochastic quantizers\n",
    "* transmission over a binary symmetric channel (BSC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are using the following device for learning: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"We are using the following device for learning:\",device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and load MNIST dataset (Preprocessing)\n",
    "Dataloader are powerful instruments, which help you to prepare your data. E.g. you can shuffle your data, transform data (standardize/normalize), divide it into batches, ...  For more information see https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader <br>\n",
    "\n",
    "In our case, we just use the dataloader to download the Dataset and preprocess the data on our own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_train = 60000      # Samples per Training Batch\n",
    "batch_size_test = 10000     # just create one large test dataset (MNIST test dataset has 10.000 Samples)\n",
    "\n",
    "# Get Training and Test Dataset with a Dataloader\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('./files/', train=True, download=True,\n",
    "  transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor()])),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('./files/', train=False, download=True,\n",
    "  transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor()])),\n",
    "  batch_size=batch_size_test, shuffle=True)\n",
    "\n",
    "# We are only interessted in the data and not in the targets\n",
    "for idx, (data, targets) in enumerate(train_loader):\n",
    "    x_train = data[:,0,:,:]\n",
    "\n",
    "for idx, (data, targets) in enumerate(test_loader):\n",
    "    x_test = data[:,0,:,:]\n",
    "\n",
    "image_size = x_train.shape[1]\n",
    "x_test_flat = torch.reshape(x_test, (x_test.shape[0], image_size*image_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot 8 random images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x144 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,2))\n",
    "for k in range(8):\n",
    "    plt.subplot(1,8,k+1)\n",
    "    plt.imshow(x_train[np.random.randint(x_train.shape[0])], interpolation='nearest', cmap='binary')\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify Autoencoder\n",
    "As explained in the lecture, we are using Stochstic Quantization. This means for the training process (*def forward*), we employ stochastic quantization in forward path but during back-propagation, we consider the quantization device as being\n",
    "non-existent (*.detach()*). While validating and testing, use deterministic quantization (*def test*) <br>\n",
    "\n",
    "\n",
    "*Note: .detach() removes the tensor from the computation graph*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_encoder_1 = 500\n",
    "hidden_encoder_2 = 250\n",
    "hidden_encoder_3 = 100\n",
    "hidden_encoder = [hidden_encoder_1, hidden_encoder_2, hidden_encoder_3]\n",
    "\n",
    "hidden_decoder_1 = 100\n",
    "hidden_decoder_2 = 250\n",
    "hidden_decoder_3 = 500\n",
    "hidden_decoder = [hidden_decoder_1, hidden_decoder_2, hidden_decoder_3]\n",
    "\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, hidden_encoder, hidden_decoder, image_size, bit_per_image):\n",
    "        super(Autoencoder, self).__init__()\n",
    "       \n",
    "        # Define Transmitter Layer: Linear function, M input neurons (symbols), 2 output neurons (real and imaginary part)        \n",
    "        self.We1 = nn.Linear(image_size*image_size, hidden_encoder[0]) \n",
    "        self.We2 = nn.Linear(hidden_encoder[0], hidden_encoder[1]) \n",
    "        self.We3 = nn.Linear(hidden_encoder[1], hidden_encoder[2]) \n",
    "        self.We4 = nn.Linear(hidden_encoder[2], bit_per_image)         \n",
    "        \n",
    "        # Define Receiver Layer: Linear function, 2 input neurons (real and imaginary part), M output neurons (symbols)\n",
    "        self.Wd1 = nn.Linear(bit_per_image,hidden_decoder[0]) \n",
    "        self.Wd2 = nn.Linear(hidden_decoder[0], hidden_decoder[1]) \n",
    "        self.Wd3 = nn.Linear(hidden_decoder[1], hidden_decoder[2]) \n",
    "        self.Wd4 = nn.Linear(hidden_decoder[2], image_size*image_size) \n",
    "\n",
    "        # Non-linearity (used in transmitter and receiver)\n",
    "        self.activation_function = nn.ELU()    \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softsign = nn.Softsign()\n",
    "        \n",
    "    def forward(self, training_data, Pe):\n",
    "        encoded = self.encoder(training_data)\n",
    "        # random binarization in training\n",
    "        ti = encoded.clone()\n",
    "        compressed = ti + (self.binarizer(ti) - ti).detach()\n",
    "        # add error pattern (flip the bit or not)\n",
    "        error_tensor = torch.distributions.Bernoulli(Pe * torch.ones_like(compressed)).sample() \n",
    "        received = torch.mul( compressed, 1 - 2*error_tensor)\n",
    "        \n",
    "        reconstructed = self.decoder(received)\n",
    "        return reconstructed\n",
    "        \n",
    "    def test(self, valid_data, Pe):\n",
    "        encoded_test = self.encoder(valid_data)\n",
    "        compressed_test = self.binarizer(encoded_test)\n",
    "        error_tensor_test = torch.distributions.Bernoulli(Pe * torch.ones_like(compressed_test)).sample()\n",
    "        received_test = torch.mul( compressed_test, 1 - 2*error_tensor_test )\n",
    "        reconstructed_test = self.decoder(received_test)\n",
    "        loss_test = torch.mean(torch.square(valid_data - reconstructed_test))\n",
    "\n",
    "        reconstructed_test_noerror = self.decoder(compressed_test)\n",
    "        return reconstructed_test\n",
    "        \n",
    "    def encoder(self, batch):\n",
    "        temp = self.activation_function(self.We1(batch))\n",
    "        temp = self.activation_function(self.We2(temp))\n",
    "        temp = self.activation_function(self.We3(temp))\n",
    "        output = self.softsign(self.We4(temp))\n",
    "        return output\n",
    "    \n",
    "    def decoder(self, batch):\n",
    "        temp = self.activation_function(self.Wd1(batch))\n",
    "        temp = self.activation_function(self.Wd2(temp))\n",
    "        temp = self.activation_function(self.Wd3(temp))\n",
    "        output = self.sigmoid(self.Wd4(temp))\n",
    "        return output\n",
    "    \n",
    "    def binarizer(self, input):\n",
    "        # This is the stochastic quatizer which we use for the training\n",
    "        return torch.sign(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function to get a random mini-batch of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(x, batch_size):\n",
    "    idxs = np.random.randint(0, x.shape[0], (batch_size))\n",
    "    return torch.stack([torch.reshape(x[k], (-1,)) for k in idxs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing ....\n",
      "Start Training\n",
      "Pe = 0.00, bits = 5, It 0: (best SNR: -2.8655 dB)\n",
      "Pe = 0.00, bits = 5, It 10000: (best SNR: 3.7106 dB)\n",
      "Pe = 0.00, bits = 5, It 20000: (best SNR: 3.7488 dB)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 250\n",
    "Pe_range = np.array([0, 0.01, 0.1, 0.2])\n",
    "bit_range = np.array([5, 10, 20, 30, 40, 50, 60, 70, 80, 100])\n",
    "\n",
    "SNR_result = np.zeros( (len(Pe_range), len(bit_range)) )\n",
    "\n",
    "# Mean Squared Error loss\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(Pe_range)):\n",
    "    for j in range(len(bit_range)):\n",
    "        best_SNR = -9999;\n",
    "        print('Initializing ....')\n",
    "        \n",
    "        model = Autoencoder(hidden_encoder, hidden_decoder, image_size, bit_range[j])\n",
    "        model.to(device)\n",
    "\n",
    "\n",
    "        # Adam Optimizer\n",
    "        optimizer = optim.Adam(model.parameters())    \n",
    "    \n",
    "        print('Start Training')   # Training loop\n",
    "\n",
    "        for it in range(100000):  # Original paper does 50k iterations  \n",
    "            mini_batch = torch.Tensor(get_batch(x_train, batch_size)).to(device)\n",
    "            # Propagate (training) data through the net\n",
    "            reconstructed = model(mini_batch, Pe_range[i])\n",
    "    \n",
    "            # compute loss\n",
    "            loss = loss_fn(mini_batch, reconstructed)\n",
    "\n",
    "            # compute gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # Adapt weights\n",
    "            optimizer.step()\n",
    "\n",
    "            # reset gradients\n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            # Evaulation with the test data\n",
    "            if it % 500 == 0:\n",
    "                reconstructed_test = model.test(x_test_flat.to(device), Pe_range[i])\n",
    "                noise =  torch.mean(torch.square(x_test_flat.to(device) - reconstructed_test))\n",
    "                SNR = 10.0 * (torch.log(torch.mean(torch.square(x_test_flat.to(device)))) - torch.log(noise)) / np.log(10.0)                \n",
    "                cur_SNR = SNR.detach().cpu().numpy().squeeze()\n",
    "                if cur_SNR > best_SNR:\n",
    "                    best_SNR = cur_SNR\n",
    "                    \n",
    "            if it % 10000 == 0:            \n",
    "                print('Pe = %1.2f, bits = %d, It %d: (best SNR: %1.4f dB)' % (Pe_range[i], bit_range[j], it, best_SNR))\n",
    "        \n",
    "        SNR_result[i,j] = best_SNR\n",
    "        print('Finished learning for e = %1.2f, bits = %d. Best SNR: %1.4f' % (Pe_range[i], bit_range[j], best_SNR))\n",
    "    \n",
    "print('Training finished')\n",
    "np.savetxt('SNR_result_simple.txt', SNR_result, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
