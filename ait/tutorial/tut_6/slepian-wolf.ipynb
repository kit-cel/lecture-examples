{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ac73597",
   "metadata": {},
   "source": [
    "# Slepian Wolf Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b406048",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2026eb79",
   "metadata": {},
   "source": [
    "\n",
    "Consider two correlated binary vectors $\\bm{X}_1$ and $\\bm{X}_2$ containing $7$ bits each.\n",
    "\n",
    "- The bits $X_{1,i}$ in $\\bm{X}_1$ are independently identically distributed (i.i.d.) with ${P(X_{1,i} = 1) = \\frac12} \\ \\forall i\\in\\{1,\\dots,7\\}$.\n",
    "- Given $\\bm{X}_1$, the vector $\\bm{X}_2$ is defined as ${\\bm{X}_2 = \\bm{X}_1 \\oplus \\bm{I}}$, where $\\bm{I}$ follows a uniform distribution over all length seven binary vectors containing at most a single $1$.\n",
    "\n",
    "The operator $\\oplus$ denotes the binary addition with $0\\oplus0 = 1\\oplus1 = 0$ and $0\\oplus1=1\\oplus0=1$ (`numpy` equivalent is the `^` 'XOR' operator).\n",
    "\n",
    "Transmitter TX1 transmits $\\bm{X}_1$ to a receiver RX via a noiseless and interference free channel at rate $R_1$.\n",
    "Simultaneously, TX2 transmits $\\bm{X}_2$ to RX at rate $R_2$.\n",
    "Note, that $\\bm{I}$ is not directly available to TX1, TX2 or RX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0583ede5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 samples of x_1:\n",
      "[[1 1 1 0 0 0 1]\n",
      " [0 1 1 1 0 0 1]\n",
      " [0 0 0 0 1 1 1]\n",
      " [0 1 0 0 1 0 0]]\n",
      "\n",
      "4 samples of x_2:\n",
      "[[1 1 1 0 0 0 1]\n",
      " [1 1 1 1 0 0 1]\n",
      " [0 0 1 0 1 1 1]\n",
      " [1 1 0 0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "def sample_x1(num_samples: int) -> np.ndarray:\n",
    "    return rng.integers(0, 2, (num_samples, 7))\n",
    "\n",
    "def sample_x2(x1: np.ndarray) -> np.ndarray:\n",
    "    num_samples = len(x1)\n",
    "    i_pos = rng.integers(0, 8, num_samples)\n",
    "    i = np.zeros_like(x1)\n",
    "    for sample_idx, one_pos in zip(range(num_samples), i_pos):\n",
    "        if one_pos < 7:\n",
    "            i[sample_idx, one_pos] = 1\n",
    "    return x1 ^ i\n",
    "\n",
    "num_samples = 4\n",
    "x1 = sample_x1(num_samples)\n",
    "x2 = sample_x2(x1)\n",
    "print(f'{num_samples} samples of x_1:')\n",
    "print(x1)\n",
    "print()\n",
    "print(f'{num_samples} samples of x_2:')\n",
    "print(x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9be2696",
   "metadata": {},
   "source": [
    "First, let TX1 and TX2 transmit $\\bm{X}_1$ and $\\bm{X}_2$ assuming they are independent.\n",
    "They must use $R_1 = R_2 = H(\\bm{X}_1) = H(\\bm{X}_2) = 7$ (bit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ecc3bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_1 = 7.0, R_2 = 7.0\n",
      "Bit error counters:\n",
      "  TX1: 0 Errors\n",
      "  TX2: 0 Errors\n"
     ]
    }
   ],
   "source": [
    "num_samples = 100\n",
    "x1_batch = sample_x1(num_samples)\n",
    "x2_batch = sample_x2(x1_batch)\n",
    "\n",
    "# TX1\n",
    "tx1_batch = x1_batch\n",
    "\n",
    "# TX2\n",
    "tx2_batch = x2_batch\n",
    "\n",
    "# Rates\n",
    "\n",
    "r1 = tx1_batch.size / num_samples\n",
    "r2 = tx2_batch.size / num_samples\n",
    "print(f'R_1 = {r1}, R_2 = {r2}')\n",
    "\n",
    "# RX\n",
    "\n",
    "x1_hat_batch = tx1_batch\n",
    "x2_hat_batch = tx2_batch\n",
    "\n",
    "# Count transmission errors\n",
    "\n",
    "tx1_errors = np.count_nonzero(x1_batch != x1_hat_batch)\n",
    "tx2_errors = np.count_nonzero(x2_batch != x2_hat_batch)\n",
    "print('Bit error counters:')\n",
    "print(f'  TX1: {tx1_errors} Errors')\n",
    "print(f'  TX2: {tx2_errors} Errors')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d252dc5",
   "metadata": {},
   "source": [
    "As $\\bm{X}_1$ and $\\bm{X}_2$ are correlated, the transmission rates can be reduced if TX2 knows both $\\bm{X}_1$ and $\\bm{X}_2$ and only transmitts the difference $\\bm{I} = \\bm{X}_1 \\oplus \\bm{X}_2$.\n",
    "In this case we can achieve the rates $R_1 = H(\\bm{X}_1) = 7$ bit and $R_2 = H(\\bm{X}_2|\\bm{X}_1) = H(\\bm{I}) = 3$ bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2c6a2a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_1 = 7.0, R_2 = 3.0\n",
      "Bit error counters:\n",
      "  TX1: 0 Errors\n",
      "  TX2: 0 Errors\n"
     ]
    }
   ],
   "source": [
    "num_samples = 100\n",
    "x1_batch = sample_x1(num_samples)\n",
    "x2_batch = sample_x2(x1_batch)\n",
    "\n",
    "def one_hot_to_bit_vector(one_hot: np.ndarray) -> np.ndarray:\n",
    "    if np.all(one_hot == 0):\n",
    "        return np.array([1, 1, 1], dtype=int)\n",
    "    position = np.argmax(one_hot)\n",
    "    bit_encoding = {0: [0, 0, 0], 1: [0, 0, 1], 2: [0, 1, 0], 3: [0, 1, 1], 4: [1, 0, 0], 5: [1, 0, 1], 6: [1, 1, 0]}\n",
    "    return np.array(bit_encoding[position], dtype=int)\n",
    "\n",
    "def bit_vector_to_one_hot(bit_vector: np.ndarray) -> np.ndarray:\n",
    "    position = np.sum(bit_vector * 2**np.arange(3)[::-1])\n",
    "    zeros = np.zeros(7, dtype=int)\n",
    "    if position < 7:\n",
    "        zeros[position] = 1\n",
    "    return zeros\n",
    "\n",
    "\n",
    "# TX1\n",
    "tx1_batch = x1_batch\n",
    "\n",
    "# TX2\n",
    "i_batch = x1_batch ^ x2_batch\n",
    "tx2_batch = np.array([one_hot_to_bit_vector(i) for i in i_batch])\n",
    "\n",
    "# Rates\n",
    "\n",
    "r1 = tx1_batch.size / num_samples\n",
    "r2 = tx2_batch.size / num_samples\n",
    "print(f'R_1 = {r1}, R_2 = {r2}')\n",
    "\n",
    "# RX\n",
    "\n",
    "x1_hat_batch = tx1_batch\n",
    "i_hat_batch = np.array([bit_vector_to_one_hot(tx2) for tx2 in tx2_batch])\n",
    "x2_hat_batch = i_hat_batch ^ x1_hat_batch\n",
    "\n",
    "# Count transmission errors\n",
    "\n",
    "tx1_errors = np.count_nonzero(x1_batch != x1_hat_batch)\n",
    "tx2_errors = np.count_nonzero(x2_batch != x2_hat_batch)\n",
    "print('Bit error counters:')\n",
    "print(f'  TX1: {tx1_errors} Errors')\n",
    "print(f'  TX2: {tx2_errors} Errors')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1fb8ed",
   "metadata": {},
   "source": [
    "According to the Slepian-Wolf Theorem, we can achieve the rate pair $R_1 = H(\\bm{X}_1)$ and $R_2 = H(\\bm{X}_2|\\bm{X}_1) < H(\\bm{X}_2)$ even if $\\bm{X}_1$ is *not* known to TX2.\n",
    "In the special case constructed here we can elegantly demonstrate this using a $(7,4)$ Hamming code.\n",
    "\n",
    "The following construction is taken from https://en.wikipedia.org/wiki/Distributed_source_coding\\#Asymmetric_case\n",
    "\n",
    ">### Background: The Hamming Code\n",
    ">\n",
    "> The $(7,4)$ Hamming code is defined as the set of seven-bit vectors $\\bm{x} = (x_1\\ x_2\\ \\dots\\ x_7)$ for which\n",
    ">$$\n",
    ">x_1 \\oplus x_2 \\oplus x_4 \\oplus x_5 = s_1,\\\\\n",
    ">x_2 \\oplus x_3 \\oplus x_4 \\oplus x_6 = s_2,\\\\\n",
    ">x_2 \\oplus x_3 \\oplus x_4 \\oplus x_7 = s_3,\n",
    ">$$\n",
    ">holds with $s_1 = s_2 = s_3 = 0$. Bit vectors contained in the code are called codewords. The $(7,4)$ Hamming code has a minimum Hamming distance of $d_\\mathrm{min} = 3$, which means that any two codewords differ in at least $3$ bits.\n",
    ">\n",
    ">For any given bit vector $\\bm{x}$, the **syndrome** is defined as $\\bm{s} = (s_1\\ s_2\\ s_3)$. (Codewords have the syndrome $\\bm{s} = (0\\ 0\\ 0)$ by definition.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "499677e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def syndrome(bit_vector: np.ndarray) -> np.ndarray:\n",
    "    x = bit_vector\n",
    "    return np.array([\n",
    "        x[0] ^ x[1] ^ x[3] ^ x[4],\n",
    "        x[0] ^ x[2] ^ x[3] ^ x[5],\n",
    "        x[1] ^ x[2] ^ x[3] ^ x[6]\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a055ba",
   "metadata": {},
   "source": [
    "Now, consider the following transmission scheme:\n",
    "\n",
    "- TX1 transmits $\\bm{X}_1\\quad\\implies R_1 = 7$ bit\n",
    "- TX2 transmits the syndrome $\\bm{S}_2$ of $\\bm{X}_2\\quad\\implies R_2 = 3$ bit\n",
    "\n",
    "Note that no knowlege of $\\bm{X}_1$ or $\\bm{I}$ is required to compute the syndrome.\n",
    "\n",
    "RX must then find possible values for $\\bm{I}$ such that $\\hat{\\bm{X}}_2 = \\bm{X}_1 \\oplus \\bm{I}$ has the syndrome $\\bm{S}_2$.\n",
    "Errors occur if multiple options for $\\hat{\\bm{X}}_2$ lead to the same syndrome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "448699e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_1 = 7.0, R_2 = 3.0\n",
      "Bit error counters:\n",
      "  TX1: 0 Errors\n",
      "  TX2: 0 Errors\n"
     ]
    }
   ],
   "source": [
    "num_samples = 100\n",
    "x1_batch = sample_x1(num_samples)\n",
    "x2_batch = sample_x2(x1_batch)\n",
    "\n",
    "\n",
    "# TX1\n",
    "tx1_batch = x1_batch\n",
    "\n",
    "# TX2\n",
    "tx2_batch = np.array([syndrome(x2) for x2 in x2_batch])\n",
    "\n",
    "# Rates\n",
    "\n",
    "r1 = tx1_batch.size / num_samples\n",
    "r2 = tx2_batch.size / num_samples\n",
    "print(f'R_1 = {r1}, R_2 = {r2}')\n",
    "\n",
    "# RX\n",
    "\n",
    "x1_hat_batch = tx1_batch\n",
    "possible_i = np.eye(8, 7, dtype=int)\n",
    "\n",
    "x2_hat_batch = []\n",
    "for x1_hat, received_syndrome in zip(x1_hat_batch, tx2_batch):\n",
    "    syndromees = np.array([syndrome(x1_hat ^ i) for i in possible_i])\n",
    "    # choose syndrome with minimum distance to received syndrome\n",
    "    best_possible_i_idx = np.argmin(np.sum((syndromees - received_syndrome)**2, axis=1))\n",
    "    i_hat = possible_i[best_possible_i_idx]\n",
    "\n",
    "    x2_hat = i_hat ^ x1_hat\n",
    "    x2_hat_batch.append(x2_hat)\n",
    "x2_hat_batch = np.array(x2_hat_batch)\n",
    "\n",
    "# Count transmission errors\n",
    "\n",
    "tx1_errors = np.count_nonzero(x1_batch != x1_hat_batch)\n",
    "tx2_errors = np.count_nonzero(x2_batch != x2_hat_batch)\n",
    "print('Bit error counters:')\n",
    "print(f'  TX1: {tx1_errors} Errors')\n",
    "print(f'  TX2: {tx2_errors} Errors')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c5666f",
   "metadata": {},
   "source": [
    "The simulation above shows that the proposed scheme produces no errors. Hence, the rate pair $R_1 = 7$ bit and $R_2 = 3$ bit is achievable even if both TX1 and TX2 only have access to either $\\bm{X}_1$ or $\\bm{X}_2$.\n",
    "\n",
    "**But why does it work?**\n",
    "\n",
    "We must show that there is never ambiguity between multiple reconstructions of $\\bm{X}_2$. This can be shown by contradiction:\n",
    "\n",
    "- Assumme ambiguity between two reconstructions of $\\bm{X}_2$, call them $\\bm{b}_1$ and $\\bm{b}_2$\n",
    "- $\\implies$ $\\texttt{syndrome}(\\bm{b}_1) = \\texttt{syndrome}(\\bm{b}_2) = \\bm{S}_2$\n",
    "- Define $\\bm{c}_1 := \\bm{b}_1 \\oplus \\bm{b}_1 = \\bm{0}$ and $\\bm{c}_2 := \\bm{b}_1 \\oplus \\bm{b}_2$\n",
    "- Claim: $\\bm{c}_1$ and $\\bm{c}_2$ are both codewords of the $(7,4)$ Hamming code\n",
    "    - Inserting $\\bm{c}_1 = \\bm{0}$ into the definition of the Hamming code immediately shows it is a codeword\n",
    "    - As both $\\bm{b}_1$ and $\\bm{b}_2$ have the same syndrome, we can show that the syndrome of $\\bm{c}_2$ is $\\bm{0}$\n",
    "        - Illustration for the first syndrome entry:\n",
    "$$\n",
    "b_{1,1} \\oplus b_{1,2} \\oplus b_{1,4} \\oplus b_{1,5} = S_{2,1} = b_{2,1} \\oplus b_{2,2} \\oplus b_{2,4} \\oplus b_{2,5} \\\\[.5em]\n",
    "b_{1,1} \\oplus b_{1,2} \\oplus b_{1,4} \\oplus b_{1,5}\\ \\ \\oplus\\ \\ b_{2,1} \\oplus b_{2,2} \\oplus b_{2,4} \\oplus b_{2,5} =b_{2,1} \\oplus b_{2,2} \\oplus b_{2,4} \\oplus b_{2,5}\\ \\ \\oplus\\ \\ b_{2,1} \\oplus b_{2,2} \\oplus b_{2,4} \\oplus b_{2,5} \\\\[.5em]\n",
    "(b_{1,1} \\oplus b_{2,1}) \\oplus (b_{1,2} \\oplus b_{2,2}) \\oplus (b_{1,4} \\oplus b_{2,4}) \\oplus (b_{1,5} \\oplus b_{2,5}) = (b_{2,1} \\oplus b_{2,1}) \\oplus (b_{2,2} \\oplus b_{2,2}) \\oplus (b_{2,4}  \\oplus b_{2,4}) \\oplus (b_{2,5}\\oplus b_{2,5}) \\\\[.5em]\n",
    "c_{2,1} \\oplus c_{2,2} \\oplus c_{2,4} \\oplus c_{2,5} = 0\n",
    "$$\n",
    "- As they are valid reconstructions of $\\bm{X}_2$, both $\\bm{b}_1$ and $\\bm{b}_2$ differ in at most $1$ bit from $\\bm{X}_1$\n",
    "- $\\implies$ $\\bm{b}_1$ and $\\bm{b}_2$ differ in at most $2$ bits\n",
    "- $\\implies$ $\\bm{c}_1$ and $\\bm{c}_2$ differ in at most $2$ bits\n",
    "- $\\implies$ Contradiction: any two codewords in the $(7,4)$ Hamming code differ in at least $3$ bits"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
